import json
import logging
import os
import openai
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# ============ –ù–ê–°–¢–†–û–ô–ö–ò ============
TELEGRAM_TOKEN = "8152914738:AAFFWy_i478GceXKqatLDFa2C3f-kaKGkXg"
OPENAI_API_KEY = "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"

openai.api_key = OPENAI_API_KEY

MEMORY_FILE = "memory.json"
MAX_HISTORY = 10  # –º–∞–∫—Å–∏–º—É–º —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏

# ============ –õ–û–ì–ò ============
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)

# ============ –ü–ê–ú–Ø–¢–¨ ============
def load_memory():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except:
            return {}
    return {}

def save_memory(memory):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory, f, ensure_ascii=False, indent=2)

user_memory = load_memory()

# ============ –ö–û–ú–ê–ù–î–´ ============
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç!\n"
        "–Ø –ò–ò-—á–∞—Ç –±–æ—Ç —Å –ø–∞–º—è—Ç—å—é üß†\n"
        "–ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ."
    )

async def clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.message.from_user.id)
    user_memory.pop(user_id, None)
    save_memory(user_memory)
    await update.message.reply_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

# ============ –ß–ê–¢ ============
async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    user_id = str(update.message.from_user.id)
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ —Ç–µ–∫—Å—Ç üôÇ")
        return

    if user_id not in user_memory:
        user_memory[user_id] = [
            {"role": "system", "content": "–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –ò–ò –ø–æ–º–æ—â–Ω–∏–∫."}
        ]

    user_memory[user_id].append({"role": "user", "content": text})

    # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏
    if len(user_memory[user_id]) > MAX_HISTORY:
        user_memory[user_id] = user_memory[user_id][-MAX_HISTORY:]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=user_memory[user_id],
            temperature=0.6,
            max_tokens=400,
            timeout=20
        )

        answer = response.choices[0].message.content.strip()
        user_memory[user_id].append({"role": "assistant", "content": answer})

        save_memory(user_memory)
        await update.message.reply_text(answer)

    except openai.error.RateLimitError:
        await update.message.reply_text("‚è≥ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ.")
    except openai.error.Timeout:
        await update.message.reply_text("‚åõÔ∏è –°–µ—Ä–≤–µ—Ä –¥–æ–ª–≥–æ –æ—Ç–≤–µ—á–∞–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
    except Exception as e:
        logging.error(e)
        await update.message.reply_text("‚ùå –û—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# ============ –ó–ê–ü–£–°–ö ============
def main():
    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("clear", clear))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))

    print("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ —Å—Ç–∞–±–∏–ª–µ–Ω")
    app.run_polling()

if __name__ == "__main__":
    main()
