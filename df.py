import os
import json
import logging
import openai
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
)

# ===================== –ù–ê–°–¢–†–û–ô–ö–ò =====================

TELEGRAM_TOKEN = os.getenv("8152914738:AAFFWy_i478GceXKqatLDFa2C3f-kaKGkXg")
OPENAI_API_KEY = os.getenv("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")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise RuntimeError("‚ùå –ù–µ –∑–∞–¥–∞–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY")

openai.api_key = OPENAI_API_KEY

MEMORY_FILE = "memory.json"
MAX_HISTORY = 12          # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
MAX_TOKENS = 400          # –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
TEMPERATURE = 0.6         # –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å

# ===================== –õ–û–ì–ò =====================

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

logger = logging.getLogger(name)

# ===================== –ü–ê–ú–Ø–¢–¨ =====================

def load_memory() -> dict:
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")
    return {}

def save_memory(memory: dict):
    try:
        with open(MEMORY_FILE, "w", encoding="utf-8") as f:
            json.dump(memory, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏: {e}")

user_memory = load_memory()

# ===================== –ö–û–ú–ê–ù–î–´ =====================

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç!\n\n"
        "–Ø –ò–ò-–±–æ—Ç —Å –ø–∞–º—è—Ç—å—é üß†\n"
        "–ú–æ–∂–µ—à—å –æ–±—â–∞—Ç—å—Å—è —Å–æ –º–Ω–æ–π –∫–∞–∫ —Å ChatGPT.\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/help ‚Äî –ø–æ–º–æ—â—å\n"
        "/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å"
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "‚ÑπÔ∏è –ü–æ–º–æ—â—å:\n\n"
        "‚Ä¢ –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏ —Ç–µ–∫—Å—Ç ‚Äî —è –æ—Ç–≤–µ—á—É\n"
        "‚Ä¢ –Ø –ø–æ–º–Ω—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞\n"
        "‚Ä¢ /clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –ø–∞–º—è—Ç—å\n\n"
        "–†–∞–±–æ—Ç–∞—é —Å—Ç–∞–±–∏–ª—å–Ω–æ –∏ 24/7 ü§ñ"
    )

async def clear(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = str(update.message.from_user.id)
    if user_id in user_memory:
        del user_memory[user_id]
        save_memory(user_memory)
    await update.message.reply_text("üßπ –ü–∞–º—è—Ç—å –æ—á–∏—â–µ–Ω–∞.")

# ===================== –û–°–ù–û–í–ù–û–ô –ß–ê–¢ =====================

async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    user_id = str(update.message.from_user.id)
    text = update.message.text.strip()

    if not text:
        await update.message.reply_text("–ù–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ üôÇ")
        return

    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
    if user_id not in user_memory:
        user_memory[user_id] = [
            {
                "role": "system",
                "content": (
                    "–¢—ã —É–º–Ω—ã–π, —Å–ø–æ–∫–æ–π–Ω—ã–π –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ò–ò –ø–æ–º–æ—â–Ω–∏–∫. "
                    "–û—Ç–≤–µ—á–∞–π –ø–æ–Ω—è—Ç–Ω–æ, —á–µ—Å—Ç–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ."
                )
            }
        ]

    user_memory[user_id].append({"role": "user", "content": text})

    # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    if len(user_memory[user_id]) > MAX_HISTORY:
        user_memory[user_id] = user_memory[user_id][-MAX_HISTORY:]

    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=user_memory[user_id],
            temperature=TEMPERATURE,
            max_tokens=MAX_TOKENS,
            timeout=20
        )

        answer = response.choices[0].message.content.strip()

        user_memory[user_id].append(
            {"role": "assistant", "content": answer}
        )

        save_memory(user_memory)

await update.message.reply_text(answer)

except openai.error.RateLimitError:
        await update.message.reply_text("‚è≥ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ.")
    except openai.error.Timeout:
        await update.message.reply_text("‚åõ –°–µ—Ä–≤–µ—Ä –¥–æ–ª–≥–æ –æ—Ç–≤–µ—á–∞–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ —á–∞—Ç–µ")
        await update.message.reply_text("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# ===================== –ó–ê–ü–£–°–ö =====================

def main():
    logger.info("ü§ñ –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞")

    app = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("clear", clear))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))

    app.run_polling()

if name == "main":
    main()
        await update.message.reply_text(answer)
